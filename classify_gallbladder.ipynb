{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af50ab5f",
   "metadata": {},
   "source": [
    "### Tryout model Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0faf0d47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///workspace/VisionWorks\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from visionworks==0.1.0) (1.8.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from visionworks==0.1.0) (0.9.1)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.8/dist-packages (from visionworks==0.1.0) (0.10.30)\n",
      "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.8/dist-packages (from visionworks==0.1.0) (0.4.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from visionworks==0.1.0) (0.3.3)\n",
      "Requirement already satisfied: scikit-image==0.18.1 in /usr/local/lib/python3.8/dist-packages (from visionworks==0.1.0) (0.18.1)\n",
      "Requirement already satisfied: Pillow==8.0.0 in /usr/local/lib/python3.8/dist-packages (from visionworks==0.1.0) (8.0.0)\n",
      "Requirement already satisfied: piexif==1.1.3 in /usr/local/lib/python3.8/dist-packages (from visionworks==0.1.0) (1.1.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from visionworks==0.1.0) (1.2.4)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.18.1->visionworks==0.1.0) (1.6.3)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.18.1->visionworks==0.1.0) (2.5.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.18.1->visionworks==0.1.0) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.18.1->visionworks==0.1.0) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.18.1->visionworks==0.1.0) (2021.4.8)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.18.1->visionworks==0.1.0) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.18.1->visionworks==0.1.0) (1.20.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->visionworks==0.1.0) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->visionworks==0.1.0) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->visionworks==0.1.0) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->visionworks==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.18.1->visionworks==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.8/dist-packages (from networkx>=2.0->scikit-image==0.18.1->visionworks==0.1.0) (4.4.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->visionworks==0.1.0) (2021.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->visionworks==0.1.0) (3.10.0.0)\n",
      "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (7.1.2)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (5.0.2)\n",
      "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (5.8.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (3.16.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (2.25.1)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (1.0.1)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (5.4.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (2.3)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (3.5.4)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb->visionworks==0.1.0) (3.1.14)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/dist-packages (from GitPython>=1.0.0->wandb->visionworks==0.1.0) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb->visionworks==0.1.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb->visionworks==0.1.0) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb->visionworks==0.1.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb->visionworks==0.1.0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb->visionworks==0.1.0) (2.10)\n",
      "Installing collected packages: visionworks\n",
      "  Attempting uninstall: visionworks\n",
      "    Found existing installation: visionworks 0.1.0\n",
      "    Can't uninstall 'visionworks'. No files were found to uninstall.\n",
      "  Running setup.py develop for visionworks\n",
      "Successfully installed visionworks-0.1.0\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install pytorch-ignite\n",
    "!pip install -e /workspace/VisionWorks\n",
    "\n",
    "#!nvidia-smi               #shell ?\n",
    "#!nvcc --version           #shell ?#\n",
    "#!pip install tqdm\n",
    "#!pip install sklearn\n",
    "#!pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cac67187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from ignite.contrib.handlers.wandb_logger import *\n",
    "from ignite.contrib.engines.common import * # does contain the setup_wandb_logging\n",
    "import os\n",
    "\n",
    "import ignite\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage, ConfusionMatrix \n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from PIL import Image\n",
    "from read_lapchol import LapcholDataset\n",
    "from matplotlib.pyplot import imshow\n",
    "#from transforms import ReadPILImage\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from visionworks.transformation.loading.image_loading import LoadPILImage\n",
    "from visionworks.transformation.image.image_transforms import ResizePILImage, ResizeNumpyImage, CenterCropTorchvision, ResizeTorchvision \n",
    "from visionworks.transformation import TorchvisionTformWrapper\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from transforms import LabelToInt, LabelToTensor, DicttoImageandLabel \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb67454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjnjsurgery\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()\n",
    "#!wandb login <13a1f666958082496c4b39a10519f6db055b76d3>\n",
    "#!wandb login --relogin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142bc41f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">classify_gallbladder</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/rubyegging/project1\" target=\"_blank\">https://wandb.ai/rubyegging/project1</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/rubyegging/project1/runs/1lmwa15r\" target=\"_blank\">https://wandb.ai/rubyegging/project1/runs/1lmwa15r</a><br/>\n",
       "                Run data is saved locally in <code>/workspace/script/wandb/run-20210521_164919-1lmwa15r</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='project1', \n",
    "        entity='rubyegging',\n",
    "    name=\"classify_gallbladder\",\n",
    "    config={  \n",
    "        \"learning_rate\": 0.0001,\n",
    "        \"epochs\": 5,\n",
    "        \"batch_size\": 16,\n",
    "        \"classes\": 2,\n",
    "        \"loss_function\": \"BCELoss\",\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"architecture\": \"Resnet50\",\n",
    "        \"dataset\": \"Lapchol_dataset\"},\n",
    "    tags=[\"pytorch-ignite\", \"lapchol\", \"try-out\"]\n",
    ")\n",
    "\n",
    "config = wandb.config\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475c2144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set:\n",
      "! Removed 0 samples with label excl\n",
      "! Removed 803 samples with label 0\n",
      "! Changed 4005 samples from 3 to 2\n",
      "Number of samples in train set:9971\n",
      "The validation set:\n",
      "! Removed 0 samples with label excl\n",
      "! Removed 147 samples with label 0\n",
      "! Changed 465 samples from 3 to 2\n",
      "Number of samples in validation set:2943\n"
     ]
    }
   ],
   "source": [
    "class_labels = [1,2]\n",
    "\n",
    "# hyperparameters in config.  \n",
    "\n",
    "# define transform\n",
    "tform = Compose([LoadPILImage(fields=['frame_path']),ResizePILImage(fields=['frame_path'], width=256, height=256), \n",
    "                 CenterCropTorchvision(fields=['frame_path'], width=224, height=224),\n",
    "                 TorchvisionTformWrapper(fields=['frame_path'], transform=ToTensor()), \n",
    "                 TorchvisionTformWrapper(fields=['frame_path'], transform=transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])),\n",
    "                 LabelToInt(fields=['label'], labels=class_labels), LabelToTensor(fields=['label']) , \n",
    "                 DicttoImageandLabel(image=['frame_path'], label=['label']) ])\n",
    "                 #])  #DicttoImageandLabel(image=['frame_path'], label=['label']\n",
    "\n",
    "# Load lapchol dataset\n",
    "print('The train set:')\n",
    "lapchol_train = LapcholDataset(root_dir='/workspace/Lapchol_dataset', incl_videos=[88,89,92,94,95,97,98,102,103,105,106,107,109,110,111,113,115,118,119,120,125,127,139,144,150,152,156,160,172,180,189,205,214,215,220,224,226,227,228], sample_rate=1,transform=tform) #70% # \n",
    "print('Number of samples in train set:' + str(lapchol_train.__len__()))\n",
    "\n",
    "print('The validation set:')\n",
    "lapchol_val = LapcholDataset(root_dir='/workspace/Lapchol_dataset', incl_videos=[242,251,286,289,292,301,302,304,309,310,315,316,358,360,367,373,407,428,444], sample_rate=1, transform=tform) #20% )#\n",
    "#lapchol_test = LapcholDataset(root_dir='D:/Ruby/Lapchol_dataset', incl_videos=[88,95], sample_rate=1) #10%\n",
    "print('Number of samples in validation set:' + str(lapchol_val.__len__()))\n",
    "\n",
    "# onderstaande nog even controleren @Fausto ? \n",
    "manualSeed = 1\n",
    "def _init_fn():\n",
    "    np.random.seed(manualSeed)\n",
    "    \n",
    "dataloader_train = DataLoader(lapchol_train, config.batch_size, shuffle=True, pin_memory=True, num_workers=0, worker_init_fn=_init_fn)\n",
    "dataloader_val = DataLoader(lapchol_val, config.batch_size, shuffle=True, pin_memory=True, num_workers=0, worker_init_fn=_init_fn) # bij validation ook shuffle=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1e0817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the first sample, as an example (only possible without transform in Dataset)\n",
    "#sample = lapchol_train.getdict()\n",
    "#print(sample)\n",
    "#print(sample[0].shape)     \n",
    "\n",
    "#print(sample.__len__())\n",
    "\n",
    "#print(sample)\n",
    "#for i in range(0,sample.__len__()):\n",
    "#    label = lapchol_train\n",
    "    #print(label.__getitem__(i)[1])     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for sample in samples:\n",
    "#    label = samples[sample]['label']\n",
    "#    print(label)\n",
    "\n",
    "#pil_img = Image.open(sample['frame_path']).convert('RGB')\n",
    "#imshow(np.asarray(pil_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d91e1342-8716-4fd8-bb6e-58604148e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22933362-8370-4968-8bf0-1de3f22e446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2460,  1.2294,  1.1120, -0.8817,  1.9755],\n",
      "        [ 0.4889, -0.1875, -0.3292,  0.9594, -0.2271],\n",
      "        [-0.0197,  0.9080, -0.9595,  0.2986, -1.5890]])\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2544a1e5-b02c-43e5-8ea5-4d6ba5b1c419",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Only possible without transforms in Dataset?\n",
    "# how much frames for each label are there in lapchol_train?\n",
    "\n",
    "total = 0\n",
    "counter_dict = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
    "for i in range(lapchol_train.__len__()):\n",
    "    sample = lapchol_train.__getitem__(i)\n",
    "    label = sample.get('label')\n",
    "    if label == 'excl':\n",
    "        label = 4\n",
    "    else:\n",
    "        label = label\n",
    "    counter_dict[int(label)] += 1\n",
    "    total += 1\n",
    "\n",
    "print(counter_dict)\n",
    "\n",
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i] / total * 100}\")\n",
    "\n",
    "total_nr_of_samples = lapchol_train.__len__()\n",
    "print(f' Total number of samples in train set: {total_nr_of_samples}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6133f535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet50(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "#for binary classification:\n",
    "model.fc = torch.nn.Sequential(torch.nn.Linear(num_ftrs, out_features=1,\n",
    "                                               bias=True), nn.Sigmoid()) #output_features=2? num_ftrs is not the same as 512?\n",
    "model.to(device)\n",
    "#print(model)\n",
    "\n",
    "\n",
    "#for multiple class classification\n",
    "#model.fc = torch.nn.Sequential(torch.nn.Linear(num_ftrs, out_features=3,\n",
    "#                                bias=True), torch.nn.Softmax(dim=1))\n",
    "\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43435fe6-c370-4e99-95a6-ae3dcb78932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beter goed gejat, dan slecht bedacht \n",
    "from ignite.metrics.metric import Metric\n",
    "from ignite.exceptions import NotComputableError\n",
    "\n",
    "\n",
    "class BinaryAccuracy(Metric):\n",
    "    \"\"\"\n",
    "    Calculates the binary accuracy.\n",
    "\n",
    "    - `update` must receive output of the form `(y_pred, y)`.\n",
    "    - `y_pred` must be in the following shape (batch_size, ...) and it's elements must be between 0 and 1.\n",
    "    - `y` must be in the following shape (batch_size, ...)\n",
    "    \"\"\"\n",
    "    def reset(self):\n",
    "        self._num_correct = 0\n",
    "        self._num_examples = 0\n",
    "\n",
    "    def update(self, output):\n",
    "        y_pred, y = output\n",
    "        correct = torch.eq(torch.round(y_pred).type(y.type()), y).view(-1)\n",
    "        self._num_correct += torch.sum(correct).item()\n",
    "        self._num_examples += correct.shape[0]\n",
    "\n",
    "    def compute(self):\n",
    "        if self._num_examples == 0:\n",
    "            raise NotComputableError('BinaryAccuracy must have at least one example before it can be computed')\n",
    "        return self._num_correct / self._num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40b59e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "optimizer = Adam(model.parameters(), config.learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "criterion = torch.nn.BCELoss()\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "epochs = config.epochs\n",
    "\n",
    "metrics = {'accuracy':BinaryAccuracy(), 'loss':Loss(criterion)} #'accuracy':Accuracy(), , 'cm':ConfusionMatrix(num_classes=len(class_labels))\n",
    "   \n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
    "train_evaluator = create_supervised_evaluator(model, metrics, device=device) \n",
    "val_evaluator = create_supervised_evaluator(model, metrics, device=device)    \n",
    "\n",
    "log_interval =5\n",
    "\n",
    "\n",
    "#from ignite.utils import setup_logger\n",
    "#trainer.logger = setup_logger(\"Train Logger\")\n",
    "  \n",
    "#training_history = {'accuracy':[],'loss':[]}\n",
    "#validation_history = {'accuracy':[],'loss':[]}\n",
    "\n",
    "#desc = \"ITERATION - loss: {:.2f}\"\n",
    "#pbar = tqdm(initial=0, leave=False, total=len(loader), desc=desc.format(0))\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=log_interval))\n",
    "def log_training_loss(engine):\n",
    "    epoch = engine.state.epoch\n",
    "    max_batches = engine.state.epoch_length\n",
    "    batch_nr = engine.state.iteration\n",
    "    batch_nr = batch_nr - (epoch - 1) * max_batches\n",
    "    loss = engine.state.output\n",
    "    wandb.log({\"train loss\": loss})\n",
    "    #pbar.desc = desc.format(engine.state.output)\n",
    "    #pbar.update(log_interval)\n",
    "    print(f'Epoch[{epoch}] Batch[{batch_nr}/{max_batches}] Loss: {loss:.4f}')\n",
    "    \n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    #pbar.refresh()\n",
    "    train_evaluator.run(dataloader_train)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    print(f\"Training Results - Epoch[{trainer.state.epoch}] Avg accuracy: {metrics['accuracy']:.2f} Avg loss: {metrics['loss']:.2f}\")\n",
    "    wandb.log({\"training loss\": metrics['loss']})\n",
    "    wandb.log({\"training accuracy\": metrics['accuracy']})\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    val_evaluator.run(dataloader_val)\n",
    "    validation_acc = val_evaluator.state.metrics[\"accuracy\"]\n",
    "    #print(\"Epoch: {} Validation accuracy: {:.2f}\".format(trainer.state.epoch, validation_acc))\n",
    "    wandb.log({\"validation loss\": metrics['loss']})\n",
    "    wandb.log({\"validation accuracy\": metrics['accuracy']})\n",
    "    \n",
    "    '''\n",
    "    Using WandBLogger in ignite is a 2-step modular process: First, you need to create \n",
    "    a WandBLogger object. Then it can be attached to any trainer or evaluator to automatically log the metrics. \n",
    "    We'll do the following tasks sequentially: 1) Create a WandBLogger object and then\n",
    "    1) Log training loss - attach to trainer\n",
    "    2) Log validation loss - attach to evaluator\n",
    "    3) Log optional Parameters\n",
    "    4) Watch the model\n",
    "    '''\n",
    "#wandb_logger.attach_output_handler(\n",
    "#trainer,\n",
    "#event_name=Events.ITERATION_COMPLETED,\n",
    "#tag=\"training\",\n",
    "#output_transform=lambda loss: {\"loss\": loss}\n",
    "#)\n",
    " \n",
    "#wandb_logger.attach_output_handler(\n",
    "#val_evaluator,\n",
    "#event_name=Events.EPOCH_COMPLETED,\n",
    "#tag=\"validation\",\n",
    "#metric_names=[\"loss\", \"accuracy\"],\n",
    "#global_step_transform=lambda *_: trainer.state.iteration,\n",
    "#)\n",
    " \n",
    "#wandb_logger.attach_opt_params_handler(\n",
    "#trainer,\n",
    "#event_name=Events.ITERATION_STARTED,\n",
    "#optimizer=optimizer,\n",
    "#param_name='lr'  # optional\n",
    "#)\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f06643b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f12086701c0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.watch(model,criterion,log=all,log_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5433f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Batch[5/624] Loss: 0.5018\n",
      "Epoch[1] Batch[10/624] Loss: 0.3810\n",
      "Epoch[1] Batch[15/624] Loss: 0.2180\n",
      "Epoch[1] Batch[20/624] Loss: 0.1451\n",
      "Epoch[1] Batch[25/624] Loss: 0.0953\n",
      "Epoch[1] Batch[30/624] Loss: 0.1743\n",
      "Epoch[1] Batch[35/624] Loss: 0.1687\n",
      "Epoch[1] Batch[40/624] Loss: 0.1045\n",
      "Epoch[1] Batch[45/624] Loss: 0.1312\n",
      "Epoch[1] Batch[50/624] Loss: 0.2402\n",
      "Epoch[1] Batch[55/624] Loss: 0.1164\n",
      "Epoch[1] Batch[60/624] Loss: 0.0458\n",
      "Epoch[1] Batch[65/624] Loss: 0.1035\n",
      "Epoch[1] Batch[70/624] Loss: 0.3127\n",
      "Epoch[1] Batch[75/624] Loss: 0.2890\n",
      "Epoch[1] Batch[80/624] Loss: 0.3840\n",
      "Epoch[1] Batch[85/624] Loss: 0.0291\n",
      "Epoch[1] Batch[90/624] Loss: 0.1459\n",
      "Epoch[1] Batch[95/624] Loss: 0.2375\n",
      "Epoch[1] Batch[100/624] Loss: 0.0170\n",
      "Epoch[1] Batch[105/624] Loss: 0.0782\n",
      "Epoch[1] Batch[110/624] Loss: 0.1284\n",
      "Epoch[1] Batch[115/624] Loss: 0.0396\n"
     ]
    }
   ],
   "source": [
    "trainer.run(dataloader_train, max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c74bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model(), 'workspace/Lapchol_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa2aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9425af2-312e-4f18-840f-ade0a78af4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b511edf-02eb-4008-b76d-7094e0c14aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
